{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys, re, math, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pickle\n",
    "import collections\n",
    "from collections import OrderedDict\n",
    "from matplotlib.pyplot import cm\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from run_experiments import *\n",
    "from datahelper import *\n",
    "import keras.metrics\n",
    "keras.metrics.cindex_score = cindex_score\n",
    "from sklearn.metrics import mean_squared_error, f1_score\n",
    "\n",
    "from keras.models import load_model \n",
    "fpath = '../data/davis/'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ligands = json.load(open(fpath+\"ligands_can.txt\"), object_pairs_hook=OrderedDict)\n",
    "proteins = json.load(open(fpath+\"proteins.txt\"), object_pairs_hook=OrderedDict)\n",
    "\n",
    "Y = pickle.load(open(fpath + \"Y\",\"rb\"), encoding='latin1') ### TODO: read from raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfmeasure = get_cindex\n",
    "runmethod = build_combined_categorical\n",
    "FLAGS = argparser()\n",
    "FLAGS.log_dir = FLAGS.log_dir + str(time.time()) + \"/\"\n",
    "FLAGS.num_windows = 32\n",
    "FLAGS.seq_window_lengths = [4]\n",
    "FLAGS.smi_window_lengths = [4]\n",
    "FLAGS.batch_size = 256\n",
    "FLAGS.num_epoch = 1000\n",
    "FLAGS.max_seq_len = 1000\n",
    "FLAGS.max_smi_len = 95\n",
    "FLAGS.dataset_path= '../data/davis/'\n",
    "FLAGS.problem_type = 1\n",
    "FLAGS.log_dir = '../logs'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ../data/davis/ start\n",
      "Read ../data/davis/ start\n",
      "68\n",
      "442\n"
     ]
    }
   ],
   "source": [
    "dataset = DataSet( fpath = FLAGS.dataset_path, ### BUNU ARGS DA GUNCELLE\n",
    "                      setting_no = FLAGS.problem_type, ##BUNU ARGS A EKLE\n",
    "                      seqlen = FLAGS.max_seq_len,\n",
    "                      smilen = FLAGS.max_smi_len,\n",
    "                      need_shuffle = False )\n",
    "# set character set size\n",
    "FLAGS.charseqset_size = dataset.charseqset_size \n",
    "FLAGS.charsmiset_size = dataset.charsmiset_size \n",
    "\n",
    "XD, XT, Y = dataset.parse_data(fpath = FLAGS.dataset_path)\n",
    "\n",
    "XD = np.asarray(XD)\n",
    "XT = np.asarray(XT)\n",
    "Y = np.asarray(Y)\n",
    "\n",
    "drugcount = XD.shape[0]\n",
    "print(drugcount)\n",
    "targetcount = XT.shape[0]\n",
    "print(targetcount)\n",
    "\n",
    "FLAGS.drug_count = drugcount\n",
    "FLAGS.target_count = targetcount\n",
    "\n",
    "label_row_inds, label_col_inds = np.where(np.isnan(Y)==False)  #basically finds the point address of affinity [x,y]\n",
    "\n",
    "if not os.path.exists(figdir):\n",
    "    os.makedirs(figdir)\n",
    "\n",
    "Y = np.mat(np.copy(Y))\n",
    "\n",
    "train_drugs, train_prots,  train_Y = prepare_interaction_pairs(XD, XT, Y, label_row_inds, label_col_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_path='../../data/'\n",
    "XD_dtc, XT_dtc, Y_dtc = get_DTC_train(data_path+'dtc_for_deepDTA.csv', FLAGS.max_smi_len, FLAGS.max_seq_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import PredefinedSplit, KFold, ParameterGrid\n",
    "def get_n_fold_by_drugs(all_drugs, n_splits=5):\n",
    "    unique_drugs = np.unique(all_drugs, axis=0)\n",
    "    test_folds = np.ones(all_drugs.shape[0])\n",
    "    kf = KFold(n_splits, random_state=15)\n",
    "    \n",
    "    j = 0\n",
    "    for _, validation_drugs in kf.split(np.arange(unique_drugs.shape[0])):\n",
    "        val_inds = []\n",
    "\n",
    "        for drug_ind in validation_drugs:\n",
    "            willbe_added =  list(np.where((~(all_drugs==unique_drugs[drug_ind, :])).sum(axis=1) == 0)[0])\n",
    "            val_inds +=   willbe_added\n",
    "        test_folds[val_inds] = j\n",
    "        j += 1\n",
    "    \n",
    "    return PredefinedSplit(test_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "all_train_drugs = np.concatenate((np.asarray(train_drugs), np.asarray(XD_dtc)), axis=0)\n",
    "all_train_prots = np.concatenate((np.asarray(train_prots), np.asarray(XT_dtc)), axis=0)\n",
    "all_train_Y = np.concatenate((np.asarray(train_Y), np.asarray(Y_dtc)), axis=0)\n",
    "all_train_Y = -np.log10(1e-8+all_train_Y/1e9)\n",
    "\n",
    "val_inds = get_n_fold_by_drugs(all_train_drugs, n_splits=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'apply_bn': False, 'filter_length': 4, 'num_filters': 24, 'dropout': 0.1}\n",
      "{'apply_bn': False, 'filter_length': 4, 'num_filters': 32, 'dropout': 0.1}\n",
      "WARNING:tensorflow:From /home/ibrahim/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1208: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/ibrahim/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1344: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Train on 37669 samples, validate on 10798 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[256,128,1,1000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/Adam/gradients/conv1d_4/convolution/Conv2D_grad/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer}} = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1d_4/convolution/ExpandDims, PermConstNHWCToNCHW-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node loss/mul/_193}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1674_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[256,128,1,1000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/Adam/gradients/conv1d_4/convolution/Conv2D_grad/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer}} = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1d_4/convolution/ExpandDims, PermConstNHWCToNCHW-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node loss/mul/_193}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1674_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a1f24ca9785c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m             gridres = gridmodel.fit(([XD_train, XT_train ]), Y_train, batch_size=FLAGS.batch_size, epochs=100, \n\u001b[1;32m     51\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXD_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXT_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                        ,callbacks=[early_stopping_callback, checkpoint_callback], verbose=2)\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mpredicted_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgridmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXD_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXT_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1646\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1648\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2350\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2351\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2352\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[256,128,1,1000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/Adam/gradients/conv1d_4/convolution/Conv2D_grad/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer}} = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv1d_4/convolution/ExpandDims, PermConstNHWCToNCHW-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node loss/mul/_193}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1674_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "from os import path\n",
    "class CustomStopper(keras.callbacks.EarlyStopping):\n",
    "    def __init__(self, monitor='val_loss',\n",
    "             min_delta=0, patience=0, verbose=0, mode='auto', start_epoch = 100): # add argument for starting epoch\n",
    "        super(CustomStopper, self).__init__()\n",
    "        self.start_epoch = start_epoch\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch > self.start_epoch:\n",
    "            super().on_epoch_end(epoch, logs)\n",
    "\n",
    "param_grid = ParameterGrid([\n",
    "    {\n",
    "        'num_filters': [24, 32, 48],\n",
    "        'filter_length': [4, 8],\n",
    "        'dropout': [0.1, 0.2, 0.3],\n",
    "        'apply_bn': [True, False]\n",
    "    }\n",
    "])\n",
    "\n",
    "results = []\n",
    "with tf.device(\"/device:GPU:0\"):\n",
    "    for ind in range(len(param_grid)):\n",
    "        params = param_grid[ind]\n",
    "        if params['apply_bn']!=False:\n",
    "            continue\n",
    "\n",
    "        print(params)\n",
    "        param_name = 'dropout'+str(params['dropout'])+'-filter_length'+str(params['filter_length'])+'-num_filters'+\\\n",
    "                    str(params['num_filters']) + '-apply_bn'+str(params['apply_bn'])\n",
    "\n",
    "        early_stopping_callback = CustomStopper(monitor='val_loss', patience=20, start_epoch=50)\n",
    "        fold_id = 0\n",
    "        for tr_fold, val_fold in val_inds.split():\n",
    "\n",
    "            model_name='checkpoints/davis_dtc_dta_'+param_name+'fold'+str(fold_id)\n",
    "            if path.exists(model_name+'.h5'):\n",
    "                continue\n",
    "            \n",
    "            checkpoint_callback = ModelCheckpoint(model_name+'.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "            if fold_id >= 3:\n",
    "                break\n",
    "            XD_train, XT_train, Y_train = all_train_drugs[tr_fold], all_train_prots[tr_fold], all_train_Y[tr_fold]\n",
    "            XD_val, XT_val, Y_val = all_train_drugs[val_fold], all_train_prots[val_fold], all_train_Y[val_fold]\n",
    "\n",
    "            gridmodel = build_combined_categorical(FLAGS, params['num_filters'], params['filter_length'], \n",
    "                                           params['filter_length'], params['dropout'], apply_bn=params['apply_bn'])\n",
    "\n",
    "            gridres = gridmodel.fit(([XD_train, XT_train ]), Y_train, batch_size=FLAGS.batch_size, epochs=100, \n",
    "                    validation_data=( ([np.array(XD_val), np.array(XT_val) ]), np.array(Y_val))\n",
    "                       ,callbacks=[early_stopping_callback, checkpoint_callback], verbose=2)\n",
    "            \n",
    "            predicted_labels = gridmodel.predict([np.array(XD_val), np.array(XT_val)])[:, 0]\n",
    "            loss, rperf2 = gridmodel.evaluate(([np.array(XD_val),np.array(XT_val) ]), np.array(Y_val), verbose=0)\n",
    "            results.append({**params, 'filename': model_name, 'fold_id': ind, 'loss': loss, 'cindex': rperf2,\n",
    "                           'rmse':  np.sqrt(mean_squared_error(Y_val, predicted_labels)),\n",
    "                           'f1': f1_score(Y_val>7, predicted_labels>7)})\n",
    "            fold_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, f1_score\n",
    "\n",
    "predicted_labels = gridmodel.predict([np.array(XD_val), np.array(XT_val) ])\n",
    "\n",
    "print('cindex:', get_cindex(Y_val, predicted_labels))\n",
    "print('rmse:', np.sqrt(mean_squared_error(Y_val, predicted_labels)))\n",
    "#print('pearsonr:', pearsonr(Y_val, predicted_labels[:, 0]))\n",
    "#print('spearmanr:', np.sqrt(spearmanr(val_Y, predicted_labels[:, 0])))\n",
    "print('f1:', np.sqrt(f1_score(Y_val>7, predicted_labels>7)))\n",
    "\n",
    "#v0.1\n",
    "#cindex: [0.81675458]\n",
    "#rmse: 0.8683109279804\n",
    "#f1: 0.6599120175960898\n",
    "#checkpoint\n",
    "#cindex: [0.79595819]\n",
    "#rmse: 0.7753355061972348\n",
    "#f1: 0.6260990336999411\n",
    "\n",
    "#v0.2\n",
    "#cindex: [0.80586742]\n",
    "#rmse: 0.8517248117216893\n",
    "#f1: 0.618852747755276\n",
    "#checkpoint\n",
    "#cindex: [0.82653753]\n",
    "#rmse: 0.7971002447060451\n",
    "#f1: 0.6114717550558165"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridmodel = load_model('checkpoints/davis_dtc_dta_b1c21098f5adaae3006535fec0f014bfold0.h5')\n",
    "XD_test, XT_test = get_DTC_train('../data/dtc_test_for_deepDTA.csv', FLAGS.max_smi_len, FLAGS.max_seq_len, with_label=False)\n",
    "XD_test, XT_test = np.asarray(XD_test), np.asarray(XT_test)\n",
    "predicted_labels = gridmodel.predict([np.array(XD_test), np.array(XT_test) ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([106., 108.,  75.,  53.,  27.,  20.,  24.,  10.,   2.,   5.]),\n",
       " array([4.77294  , 5.172059 , 5.571178 , 5.970297 , 6.3694158, 6.7685347,\n",
       "        7.167654 , 7.566773 , 7.965892 , 8.36501  , 8.76413  ],\n",
       "       dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9f66671710>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data = pd.read_csv(data_path+'round_1_template.csv')\n",
    "submission_data.loc[:, 'pKd_[M]_pred'] = predicted_labels\n",
    "submission_data.to_csv(data_path+'submission_file1.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
