{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys, re, math, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pickle\n",
    "import collections\n",
    "from collections import OrderedDict\n",
    "from matplotlib.pyplot import cm\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from run_experiments import *\n",
    "from datahelper import *\n",
    "import keras.metrics\n",
    "keras.metrics.cindex_score = cindex_score\n",
    "from keras.models import load_model \n",
    "fpath = '../data/davis/'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ligands = json.load(open(fpath+\"ligands_can.txt\"), object_pairs_hook=OrderedDict)\n",
    "proteins = json.load(open(fpath+\"proteins.txt\"), object_pairs_hook=OrderedDict)\n",
    "\n",
    "Y = pickle.load(open(fpath + \"Y\",\"rb\"), encoding='latin1') ### TODO: read from raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfmeasure = get_cindex\n",
    "runmethod = build_combined_categorical\n",
    "FLAGS = argparser()\n",
    "FLAGS.log_dir = FLAGS.log_dir + str(time.time()) + \"/\"\n",
    "FLAGS.num_windows = 32\n",
    "FLAGS.seq_window_lengths = [4]\n",
    "FLAGS.smi_window_lengths = [4]\n",
    "FLAGS.batch_size = 256\n",
    "FLAGS.num_epoch = 100\n",
    "FLAGS.max_seq_len = 1000\n",
    "FLAGS.max_smi_len = 100\n",
    "FLAGS.dataset_path= '../data/davis/'\n",
    "FLAGS.problem_type = 1\n",
    "FLAGS.log_dir = '../logs'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ../data/davis/ start\n",
      "Read ../data/davis/ start\n",
      "68\n",
      "442\n",
      "Reading ../data/davis/ start\n",
      "val set 5010\n",
      "train set 20036\n"
     ]
    }
   ],
   "source": [
    "dataset = DataSet( fpath = FLAGS.dataset_path, ### BUNU ARGS DA GUNCELLE\n",
    "                      setting_no = FLAGS.problem_type, ##BUNU ARGS A EKLE\n",
    "                      seqlen = FLAGS.max_seq_len,\n",
    "                      smilen = FLAGS.max_smi_len,\n",
    "                      need_shuffle = False )\n",
    "# set character set size\n",
    "FLAGS.charseqset_size = dataset.charseqset_size \n",
    "FLAGS.charsmiset_size = dataset.charsmiset_size \n",
    "\n",
    "XD, XT, Y = dataset.parse_data(fpath = FLAGS.dataset_path)\n",
    "\n",
    "XD = np.asarray(XD)\n",
    "XT = np.asarray(XT)\n",
    "Y = np.asarray(Y)\n",
    "\n",
    "drugcount = XD.shape[0]\n",
    "print(drugcount)\n",
    "targetcount = XT.shape[0]\n",
    "print(targetcount)\n",
    "\n",
    "FLAGS.drug_count = drugcount\n",
    "FLAGS.target_count = targetcount\n",
    "\n",
    "label_row_inds, label_col_inds = np.where(np.isnan(Y)==False)  #basically finds the point address of affinity [x,y]\n",
    "\n",
    "if not os.path.exists(figdir):\n",
    "    os.makedirs(figdir)\n",
    "test_set, outer_train_sets = dataset.read_sets(FLAGS.dataset_path, FLAGS.problem_type) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logging(\"---Parameter Search-----\", FLAGS)\n",
    "\n",
    "Y = np.mat(np.copy(Y))\n",
    "\n",
    "params = {}\n",
    "\n",
    "XD = XD[label_row_inds]\n",
    "XT = XT[label_col_inds]\n",
    "\n",
    "train_drugs, train_prots,  train_Y = prepare_interaction_pairs(XD, XT, Y, label_row_inds, label_col_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_path='../../data/'\n",
    "XD_dtc, XT_dtc, Y_dtc = get_DTC_train(data_path+'dtc_for_deepDTA.csv', FLAGS.max_smi_len, FLAGS.max_seq_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "all_train_drugs = np.concatenate((np.asarray(train_drugs), np.asarray(XD_dtc)), axis=0)\n",
    "all_train_prots = np.concatenate((np.asarray(train_prots), np.asarray(XT_dtc)), axis=0)\n",
    "all_train_Y = np.concatenate((np.asarray(train_Y), np.asarray(Y_dtc)), axis=0)\n",
    "all_train_Y = -np.log10(1e-8+all_train_Y/1e9)\n",
    "\n",
    "XD_train, XD_val, XT_train, XT_val, Y_train, Y_val = train_test_split(all_train_drugs, all_train_prots, all_train_Y, \n",
    "                                                                      test_size=0.1, \n",
    "                                                                     random_state=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 51395 samples, validate on 5711 samples\n",
      "Epoch 1/1000\n",
      "Epoch 00001: val_loss improved from inf to 2.25803, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 46s - loss: 1.2989 - cindex_score: 0.6293 - val_loss: 2.2580 - val_cindex_score: 0.4955\n",
      "Epoch 2/1000\n",
      "Epoch 00002: val_loss improved from 2.25803 to 0.76028, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 38s - loss: 0.6249 - cindex_score: 0.6759 - val_loss: 0.7603 - val_cindex_score: 0.4783\n",
      "Epoch 3/1000\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 38s - loss: 0.5492 - cindex_score: 0.6989 - val_loss: 2.3011 - val_cindex_score: 0.5860\n",
      "Epoch 4/1000\n",
      "Epoch 00004: val_loss improved from 0.76028 to 0.55174, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 38s - loss: 0.5078 - cindex_score: 0.7178 - val_loss: 0.5517 - val_cindex_score: 0.6980\n",
      "Epoch 5/1000\n",
      "Epoch 00005: val_loss improved from 0.55174 to 0.51736, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 38s - loss: 0.4927 - cindex_score: 0.7262 - val_loss: 0.5174 - val_cindex_score: 0.7265\n",
      "Epoch 6/1000\n",
      "Epoch 00006: val_loss improved from 0.51736 to 0.46455, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 38s - loss: 0.4672 - cindex_score: 0.7373 - val_loss: 0.4646 - val_cindex_score: 0.7370\n",
      "Epoch 7/1000\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 38s - loss: 0.4483 - cindex_score: 0.7468 - val_loss: 0.4747 - val_cindex_score: 0.7418\n",
      "Epoch 8/1000\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 38s - loss: 0.4545 - cindex_score: 0.7430 - val_loss: 0.4916 - val_cindex_score: 0.7419\n",
      "Epoch 9/1000\n",
      "Epoch 00009: val_loss improved from 0.46455 to 0.45461, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 38s - loss: 0.4447 - cindex_score: 0.7489 - val_loss: 0.4546 - val_cindex_score: 0.7566\n",
      "Epoch 10/1000\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 38s - loss: 0.4217 - cindex_score: 0.7632 - val_loss: 0.4798 - val_cindex_score: 0.7432\n",
      "Epoch 11/1000\n",
      "Epoch 00011: val_loss improved from 0.45461 to 0.45021, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 38s - loss: 0.4179 - cindex_score: 0.7630 - val_loss: 0.4502 - val_cindex_score: 0.7635\n",
      "Epoch 12/1000\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 38s - loss: 0.4207 - cindex_score: 0.7619 - val_loss: 0.4549 - val_cindex_score: 0.7506\n",
      "Epoch 13/1000\n",
      "Epoch 00013: val_loss improved from 0.45021 to 0.43487, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 38s - loss: 0.4131 - cindex_score: 0.7656 - val_loss: 0.4349 - val_cindex_score: 0.7488\n",
      "Epoch 14/1000\n",
      "Epoch 00014: val_loss improved from 0.43487 to 0.42868, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 38s - loss: 0.4068 - cindex_score: 0.7701 - val_loss: 0.4287 - val_cindex_score: 0.7691\n",
      "Epoch 15/1000\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 38s - loss: 0.4016 - cindex_score: 0.7716 - val_loss: 0.4487 - val_cindex_score: 0.7558\n",
      "Epoch 16/1000\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 38s - loss: 0.4004 - cindex_score: 0.7746 - val_loss: 0.4378 - val_cindex_score: 0.7636\n",
      "Epoch 17/1000\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 38s - loss: 0.3968 - cindex_score: 0.7739 - val_loss: 0.4496 - val_cindex_score: 0.7574\n",
      "Epoch 18/1000\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 38s - loss: 0.3977 - cindex_score: 0.7774 - val_loss: 0.4453 - val_cindex_score: 0.7458\n",
      "Epoch 19/1000\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 38s - loss: 0.3921 - cindex_score: 0.7795 - val_loss: 0.4777 - val_cindex_score: 0.7352\n",
      "Epoch 20/1000\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 38s - loss: 0.4000 - cindex_score: 0.7759 - val_loss: 0.4450 - val_cindex_score: 0.7713\n",
      "Epoch 21/1000\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 38s - loss: 0.3904 - cindex_score: 0.7787 - val_loss: 0.4346 - val_cindex_score: 0.7634\n",
      "Epoch 22/1000\n",
      "Epoch 00022: val_loss improved from 0.42868 to 0.42802, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 38s - loss: 0.3922 - cindex_score: 0.7801 - val_loss: 0.4280 - val_cindex_score: 0.7623\n",
      "Epoch 23/1000\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 38s - loss: 0.3840 - cindex_score: 0.7821 - val_loss: 0.4345 - val_cindex_score: 0.7491\n",
      "Epoch 24/1000\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 38s - loss: 0.3856 - cindex_score: 0.7843 - val_loss: 0.4407 - val_cindex_score: 0.7387\n",
      "Epoch 25/1000\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 38s - loss: 0.3880 - cindex_score: 0.7819 - val_loss: 0.4666 - val_cindex_score: 0.7392\n",
      "Epoch 26/1000\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 38s - loss: 0.3854 - cindex_score: 0.7828 - val_loss: 0.4374 - val_cindex_score: 0.7684\n",
      "Epoch 27/1000\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 38s - loss: 0.3813 - cindex_score: 0.7853 - val_loss: 0.4300 - val_cindex_score: 0.7612\n",
      "Epoch 28/1000\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 38s - loss: 0.3816 - cindex_score: 0.7863 - val_loss: 0.4374 - val_cindex_score: 0.7427\n",
      "Epoch 29/1000\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 38s - loss: 0.3799 - cindex_score: 0.7876 - val_loss: 0.4438 - val_cindex_score: 0.7576\n",
      "Epoch 30/1000\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 38s - loss: 0.3784 - cindex_score: 0.7872 - val_loss: 0.4315 - val_cindex_score: 0.7587\n",
      "Epoch 31/1000\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 38s - loss: 0.3763 - cindex_score: 0.7908 - val_loss: 0.4283 - val_cindex_score: 0.7656\n",
      "Epoch 32/1000\n",
      "Epoch 00032: val_loss improved from 0.42802 to 0.42393, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 38s - loss: 0.3774 - cindex_score: 0.7870 - val_loss: 0.4239 - val_cindex_score: 0.7733\n",
      "Epoch 33/1000\n",
      "Epoch 00033: val_loss improved from 0.42393 to 0.41810, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 38s - loss: 0.3770 - cindex_score: 0.7877 - val_loss: 0.4181 - val_cindex_score: 0.7698\n",
      "Epoch 34/1000\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 38s - loss: 0.3719 - cindex_score: 0.7924 - val_loss: 0.4248 - val_cindex_score: 0.7563\n",
      "Epoch 35/1000\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 38s - loss: 0.3715 - cindex_score: 0.7913 - val_loss: 0.4192 - val_cindex_score: 0.7682\n",
      "Epoch 36/1000\n",
      "Epoch 00036: val_loss improved from 0.41810 to 0.41746, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 38s - loss: 0.3694 - cindex_score: 0.7945 - val_loss: 0.4175 - val_cindex_score: 0.7742\n",
      "Epoch 37/1000\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 38s - loss: 0.3736 - cindex_score: 0.7927 - val_loss: 0.4221 - val_cindex_score: 0.7713\n",
      "Epoch 38/1000\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 38s - loss: 0.3654 - cindex_score: 0.7983 - val_loss: 0.4269 - val_cindex_score: 0.7651\n",
      "Epoch 39/1000\n",
      "Epoch 00039: val_loss improved from 0.41746 to 0.41643, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 38s - loss: 0.3713 - cindex_score: 0.7919 - val_loss: 0.4164 - val_cindex_score: 0.7741\n",
      "Epoch 40/1000\n",
      "Epoch 00040: val_loss improved from 0.41643 to 0.41488, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 38s - loss: 0.3629 - cindex_score: 0.7980 - val_loss: 0.4149 - val_cindex_score: 0.7722\n",
      "Epoch 41/1000\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 38s - loss: 0.3627 - cindex_score: 0.7982 - val_loss: 0.4175 - val_cindex_score: 0.7749\n",
      "Epoch 42/1000\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 38s - loss: 0.3654 - cindex_score: 0.7970 - val_loss: 0.4258 - val_cindex_score: 0.7759\n",
      "Epoch 43/1000\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 38s - loss: 0.3625 - cindex_score: 0.7982 - val_loss: 0.4164 - val_cindex_score: 0.7757\n",
      "Epoch 44/1000\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 38s - loss: 0.3607 - cindex_score: 0.7997 - val_loss: 0.4152 - val_cindex_score: 0.7683\n",
      "Epoch 45/1000\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 38s - loss: 0.3645 - cindex_score: 0.7971 - val_loss: 0.4182 - val_cindex_score: 0.7752\n",
      "Epoch 46/1000\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 38s - loss: 0.3589 - cindex_score: 0.8009 - val_loss: 0.4221 - val_cindex_score: 0.7700\n",
      "Epoch 47/1000\n",
      "Epoch 00047: val_loss improved from 0.41488 to 0.41220, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 38s - loss: 0.3569 - cindex_score: 0.8015 - val_loss: 0.4122 - val_cindex_score: 0.7820\n",
      "Epoch 48/1000\n",
      "Epoch 00048: val_loss improved from 0.41220 to 0.41095, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 38s - loss: 0.3588 - cindex_score: 0.8030 - val_loss: 0.4109 - val_cindex_score: 0.7733\n",
      "Epoch 49/1000\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 38s - loss: 0.3600 - cindex_score: 0.8017 - val_loss: 0.4128 - val_cindex_score: 0.7769\n",
      "Epoch 50/1000\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 38s - loss: 0.3607 - cindex_score: 0.8011 - val_loss: 0.4148 - val_cindex_score: 0.7729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/1000\n",
      "Epoch 00051: val_loss improved from 0.41095 to 0.40865, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 38s - loss: 0.3540 - cindex_score: 0.8062 - val_loss: 0.4086 - val_cindex_score: 0.7738\n",
      "Epoch 52/1000\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 38s - loss: 0.3557 - cindex_score: 0.8053 - val_loss: 0.4387 - val_cindex_score: 0.7560\n",
      "Epoch 53/1000\n",
      "Epoch 00053: val_loss improved from 0.40865 to 0.40716, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 38s - loss: 0.3535 - cindex_score: 0.8046 - val_loss: 0.4072 - val_cindex_score: 0.7819\n",
      "Epoch 54/1000\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 38s - loss: 0.3531 - cindex_score: 0.8062 - val_loss: 0.4116 - val_cindex_score: 0.7791\n",
      "Epoch 55/1000\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 38s - loss: 0.3535 - cindex_score: 0.8060 - val_loss: 0.4205 - val_cindex_score: 0.7720\n",
      "Epoch 56/1000\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 38s - loss: 0.3536 - cindex_score: 0.8069 - val_loss: 0.4173 - val_cindex_score: 0.7725\n",
      "Epoch 57/1000\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 38s - loss: 0.3482 - cindex_score: 0.8101 - val_loss: 0.4087 - val_cindex_score: 0.7726\n",
      "Epoch 58/1000\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 38s - loss: 0.3490 - cindex_score: 0.8092 - val_loss: 0.4176 - val_cindex_score: 0.7695\n",
      "Epoch 59/1000\n",
      "Epoch 00059: val_loss improved from 0.40716 to 0.40647, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 38s - loss: 0.3518 - cindex_score: 0.8069 - val_loss: 0.4065 - val_cindex_score: 0.7846\n",
      "Epoch 60/1000\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 38s - loss: 0.3502 - cindex_score: 0.8096 - val_loss: 0.4087 - val_cindex_score: 0.7854\n",
      "Epoch 61/1000\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 38s - loss: 0.3485 - cindex_score: 0.8115 - val_loss: 0.4073 - val_cindex_score: 0.7806\n",
      "Epoch 62/1000\n",
      "Epoch 00062: val_loss improved from 0.40647 to 0.40198, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 38s - loss: 0.3484 - cindex_score: 0.8089 - val_loss: 0.4020 - val_cindex_score: 0.7789\n",
      "Epoch 63/1000\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 38s - loss: 0.3510 - cindex_score: 0.8102 - val_loss: 0.4043 - val_cindex_score: 0.7798\n",
      "Epoch 64/1000\n",
      "Epoch 00064: val_loss improved from 0.40198 to 0.39990, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 38s - loss: 0.3478 - cindex_score: 0.8105 - val_loss: 0.3999 - val_cindex_score: 0.7854\n",
      "Epoch 65/1000\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 38s - loss: 0.3453 - cindex_score: 0.8119 - val_loss: 0.4101 - val_cindex_score: 0.7807\n",
      "Epoch 66/1000\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 38s - loss: 0.3468 - cindex_score: 0.8116 - val_loss: 0.4106 - val_cindex_score: 0.7877\n",
      "Epoch 67/1000\n",
      "Epoch 00067: val_loss did not improve\n",
      " - 38s - loss: 0.3478 - cindex_score: 0.8107 - val_loss: 0.4059 - val_cindex_score: 0.7796\n",
      "Epoch 68/1000\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 38s - loss: 0.3462 - cindex_score: 0.8126 - val_loss: 0.4103 - val_cindex_score: 0.7811\n",
      "Epoch 69/1000\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 38s - loss: 0.3443 - cindex_score: 0.8145 - val_loss: 0.4040 - val_cindex_score: 0.7880\n",
      "Epoch 70/1000\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 38s - loss: 0.3454 - cindex_score: 0.8123 - val_loss: 0.4094 - val_cindex_score: 0.7766\n",
      "Epoch 71/1000\n",
      "Epoch 00071: val_loss did not improve\n",
      " - 38s - loss: 0.3493 - cindex_score: 0.8117 - val_loss: 0.4079 - val_cindex_score: 0.7845\n",
      "Epoch 72/1000\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 38s - loss: 0.3461 - cindex_score: 0.8123 - val_loss: 0.4038 - val_cindex_score: 0.7821\n",
      "Epoch 73/1000\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 38s - loss: 0.3441 - cindex_score: 0.8137 - val_loss: 0.4152 - val_cindex_score: 0.7719\n",
      "Epoch 74/1000\n",
      "Epoch 00074: val_loss did not improve\n",
      " - 38s - loss: 0.3456 - cindex_score: 0.8140 - val_loss: 0.4013 - val_cindex_score: 0.7803\n"
     ]
    }
   ],
   "source": [
    "model_name='checkpoints/davis_dtc_dta'\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
    "checkpoint_callback = ModelCheckpoint(model_name+'.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "gridmodel = build_combined_categorical(FLAGS, FLAGS.num_windows, FLAGS.smi_window_lengths[0], FLAGS.seq_window_lengths[0])\n",
    "gridres = gridmodel.fit(([XD_train, XT_train ]), Y_train, batch_size=FLAGS.batch_size, epochs=1000, \n",
    "        validation_data=( ([np.array(XD_val), np.array(XT_val) ]), np.array(Y_val))\n",
    "           , callbacks=[early_stopping_callback, checkpoint_callback], verbose=2)\n",
    "\n",
    "gridmodel.save('davis_dtc_dta.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, auc, f1_score\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "gridmodel = load_model('davis_dtc_dta.h5')\n",
    "predicted_labels = gridmodel.predict([np.array(XD_val), np.array(XT_val) ])\n",
    "loss, rperf2 = gridmodel.evaluate(([np.array(XD_val),np.array(XT_val) ]), np.array(Y_val), verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cindex: [0.77902714]\n",
      "rmse: 0.6334978811975447\n",
      "f1: 0.7442827651721986\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = gridmodel.predict([np.array(XD_val), np.array(XT_val) ])\n",
    "print('cindex:', get_cindex(Y_val, predicted_labels))\n",
    "print('rmse:', np.sqrt(mean_squared_error(Y_val, predicted_labels)))\n",
    "#print('pearsonr:', pearsonr(Y_val, predicted_labels[:, 0]))\n",
    "#print('spearmanr:', np.sqrt(spearmanr(val_Y, predicted_labels[:, 0])))\n",
    "print('f1:', np.sqrt(f1_score(Y_val>7, predicted_labels>7)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "XD_test, XT_test = get_DTC_train(data_path+'dtc_test_for_deepDTA.csv', FLAGS.max_smi_len, FLAGS.max_seq_len, with_label=False)\n",
    "XD_test, XT_test = np.asarray(XD_test), np.asarray(XT_test)\n",
    "predicted_labels = gridmodel.predict([np.array(XD_test), np.array(XT_test) ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data = pd.read_csv(data_path+'round_1_template.csv')\n",
    "submission_data.loc[:, 'pKd_[M]_pred'] = predicted_labels\n",
    "submission_data.to_csv(data_path+'submission_file.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
