{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys, re, math, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pickle\n",
    "import collections\n",
    "from collections import OrderedDict\n",
    "from matplotlib.pyplot import cm\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from run_experiments import *\n",
    "from datahelper import *\n",
    "import keras.metrics\n",
    "keras.metrics.cindex_score = cindex_score\n",
    "from keras.models import load_model \n",
    "fpath = '../data/davis/'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ligands = json.load(open(fpath+\"ligands_can.txt\"), object_pairs_hook=OrderedDict)\n",
    "proteins = json.load(open(fpath+\"proteins.txt\"), object_pairs_hook=OrderedDict)\n",
    "\n",
    "Y = pickle.load(open(fpath + \"Y\",\"rb\"), encoding='latin1') ### TODO: read from raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfmeasure = get_cindex\n",
    "runmethod = build_combined_categorical\n",
    "FLAGS = argparser()\n",
    "FLAGS.log_dir = FLAGS.log_dir + str(time.time()) + \"/\"\n",
    "FLAGS.num_windows = 32\n",
    "FLAGS.seq_window_lengths = [4]\n",
    "FLAGS.smi_window_lengths = [4]\n",
    "FLAGS.batch_size = 256\n",
    "FLAGS.num_epoch = 100\n",
    "FLAGS.max_seq_len = 1000\n",
    "FLAGS.max_smi_len = 100\n",
    "FLAGS.dataset_path= '../data/davis/'\n",
    "FLAGS.problem_type = 1\n",
    "FLAGS.log_dir = '../logs'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ../data/davis/ start\n",
      "Read ../data/davis/ start\n",
      "68\n",
      "442\n",
      "Reading ../data/davis/ start\n"
     ]
    }
   ],
   "source": [
    "dataset = DataSet( fpath = FLAGS.dataset_path, ### BUNU ARGS DA GUNCELLE\n",
    "                      setting_no = FLAGS.problem_type, ##BUNU ARGS A EKLE\n",
    "                      seqlen = FLAGS.max_seq_len,\n",
    "                      smilen = FLAGS.max_smi_len,\n",
    "                      need_shuffle = False )\n",
    "# set character set size\n",
    "FLAGS.charseqset_size = dataset.charseqset_size \n",
    "FLAGS.charsmiset_size = dataset.charsmiset_size \n",
    "\n",
    "XD, XT, Y = dataset.parse_data(fpath = FLAGS.dataset_path)\n",
    "\n",
    "XD = np.asarray(XD)\n",
    "XT = np.asarray(XT)\n",
    "Y = np.asarray(Y)\n",
    "\n",
    "drugcount = XD.shape[0]\n",
    "print(drugcount)\n",
    "targetcount = XT.shape[0]\n",
    "print(targetcount)\n",
    "\n",
    "FLAGS.drug_count = drugcount\n",
    "FLAGS.target_count = targetcount\n",
    "\n",
    "label_row_inds, label_col_inds = np.where(np.isnan(Y)==False)  #basically finds the point address of affinity [x,y]\n",
    "\n",
    "if not os.path.exists(figdir):\n",
    "    os.makedirs(figdir)\n",
    "test_set, outer_train_sets = dataset.read_sets(FLAGS.dataset_path, FLAGS.problem_type) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logging(\"---Parameter Search-----\", FLAGS)\n",
    "\n",
    "Y = np.mat(np.copy(Y))\n",
    "\n",
    "params = {}\n",
    "\n",
    "train_drugs, train_prots,  train_Y = prepare_interaction_pairs(XD, XT, Y, label_row_inds, label_col_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_path='../../data/'\n",
    "XD_dtc, XT_dtc, Y_dtc = get_DTC_train(data_path+'dtc_for_deepDTA.csv', FLAGS.max_smi_len, FLAGS.max_seq_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "all_train_drugs = np.concatenate((np.asarray(train_drugs), np.asarray(XD_dtc)), axis=0)\n",
    "all_train_prots = np.concatenate((np.asarray(train_prots), np.asarray(XT_dtc)), axis=0)\n",
    "all_train_Y = np.concatenate((np.asarray(train_Y), np.asarray(Y_dtc)), axis=0)\n",
    "all_train_Y = -np.log10(all_train_Y/1e9)\n",
    "\n",
    "XD_train, XD_val, XT_train, XT_val, Y_train, Y_val = train_test_split(all_train_drugs, all_train_prots, all_train_Y, \n",
    "                                                                      test_size=0.1, \n",
    "                                                                     random_state=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ibrahim/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1208: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/ibrahim/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1344: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Train on 41310 samples, validate on 4591 samples\n",
      "Epoch 1/1000\n",
      "Epoch 00001: val_loss improved from inf to 0.88949, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 36s - loss: 2.0722 - cindex_score: 0.5301 - val_loss: 0.8895 - val_cindex_score: 0.4842\n",
      "Epoch 2/1000\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 30s - loss: 1.0628 - cindex_score: 0.5643 - val_loss: 1.0610 - val_cindex_score: 0.5156\n",
      "Epoch 3/1000\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 30s - loss: 0.9197 - cindex_score: 0.5952 - val_loss: 1.5839 - val_cindex_score: 0.5760\n",
      "Epoch 4/1000\n",
      "Epoch 00004: val_loss improved from 0.88949 to 0.85833, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 30s - loss: 0.8775 - cindex_score: 0.6119 - val_loss: 0.8583 - val_cindex_score: 0.6624\n",
      "Epoch 5/1000\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 30s - loss: 0.8313 - cindex_score: 0.6268 - val_loss: 0.8945 - val_cindex_score: 0.6622\n",
      "Epoch 6/1000\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 30s - loss: 0.7751 - cindex_score: 0.6442 - val_loss: 1.1857 - val_cindex_score: 0.6329\n",
      "Epoch 7/1000\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 29s - loss: 0.7405 - cindex_score: 0.6558 - val_loss: 1.1613 - val_cindex_score: 0.6342\n",
      "Epoch 8/1000\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 30s - loss: 0.7323 - cindex_score: 0.6625 - val_loss: 0.9321 - val_cindex_score: 0.6861\n",
      "Epoch 9/1000\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 29s - loss: 0.7237 - cindex_score: 0.6687 - val_loss: 0.9642 - val_cindex_score: 0.7119\n",
      "Epoch 10/1000\n",
      "Epoch 00010: val_loss improved from 0.85833 to 0.80325, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 30s - loss: 0.6968 - cindex_score: 0.6745 - val_loss: 0.8032 - val_cindex_score: 0.6946\n",
      "Epoch 11/1000\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 29s - loss: 0.6851 - cindex_score: 0.6825 - val_loss: 0.9885 - val_cindex_score: 0.6688\n",
      "Epoch 12/1000\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 29s - loss: 0.6869 - cindex_score: 0.6821 - val_loss: 0.9030 - val_cindex_score: 0.6602\n",
      "Epoch 13/1000\n",
      "Epoch 00013: val_loss improved from 0.80325 to 0.71994, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 30s - loss: 0.6769 - cindex_score: 0.6865 - val_loss: 0.7199 - val_cindex_score: 0.7024\n",
      "Epoch 14/1000\n",
      "Epoch 00014: val_loss improved from 0.71994 to 0.69070, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 30s - loss: 0.6598 - cindex_score: 0.6924 - val_loss: 0.6907 - val_cindex_score: 0.7214\n",
      "Epoch 15/1000\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 30s - loss: 0.6543 - cindex_score: 0.6995 - val_loss: 0.8463 - val_cindex_score: 0.6800\n",
      "Epoch 16/1000\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 29s - loss: 0.6702 - cindex_score: 0.6944 - val_loss: 0.7417 - val_cindex_score: 0.7040\n",
      "Epoch 17/1000\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 30s - loss: 0.6477 - cindex_score: 0.7025 - val_loss: 0.6943 - val_cindex_score: 0.7215\n",
      "Epoch 18/1000\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 29s - loss: 0.6378 - cindex_score: 0.7044 - val_loss: 0.7067 - val_cindex_score: 0.6984\n",
      "Epoch 19/1000\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 30s - loss: 0.6385 - cindex_score: 0.7058 - val_loss: 0.6981 - val_cindex_score: 0.7104\n",
      "Epoch 20/1000\n",
      "Epoch 00020: val_loss improved from 0.69070 to 0.66501, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 30s - loss: 0.6391 - cindex_score: 0.7057 - val_loss: 0.6650 - val_cindex_score: 0.6980\n",
      "Epoch 21/1000\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 30s - loss: 0.6282 - cindex_score: 0.7072 - val_loss: 0.6793 - val_cindex_score: 0.7188\n",
      "Epoch 22/1000\n",
      "Epoch 00022: val_loss improved from 0.66501 to 0.63427, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 30s - loss: 0.6347 - cindex_score: 0.7067 - val_loss: 0.6343 - val_cindex_score: 0.7266\n",
      "Epoch 23/1000\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 29s - loss: 0.6175 - cindex_score: 0.7117 - val_loss: 0.6545 - val_cindex_score: 0.6886\n",
      "Epoch 24/1000\n",
      "Epoch 00024: val_loss improved from 0.63427 to 0.63249, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 30s - loss: 0.6275 - cindex_score: 0.7104 - val_loss: 0.6325 - val_cindex_score: 0.7315\n",
      "Epoch 25/1000\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 29s - loss: 0.6177 - cindex_score: 0.7136 - val_loss: 0.6595 - val_cindex_score: 0.7167\n",
      "Epoch 26/1000\n",
      "Epoch 00026: val_loss improved from 0.63249 to 0.62189, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 30s - loss: 0.6224 - cindex_score: 0.7127 - val_loss: 0.6219 - val_cindex_score: 0.7177\n",
      "Epoch 27/1000\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 29s - loss: 0.6109 - cindex_score: 0.7191 - val_loss: 0.6790 - val_cindex_score: 0.6956\n",
      "Epoch 28/1000\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 30s - loss: 0.6079 - cindex_score: 0.7170 - val_loss: 0.6434 - val_cindex_score: 0.7179\n",
      "Epoch 29/1000\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 29s - loss: 0.6021 - cindex_score: 0.7177 - val_loss: 0.6505 - val_cindex_score: 0.7108\n",
      "Epoch 30/1000\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 29s - loss: 0.6002 - cindex_score: 0.7236 - val_loss: 0.6504 - val_cindex_score: 0.7197\n",
      "Epoch 31/1000\n",
      "Epoch 00031: val_loss improved from 0.62189 to 0.61815, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 30s - loss: 0.6061 - cindex_score: 0.7218 - val_loss: 0.6181 - val_cindex_score: 0.7154\n",
      "Epoch 32/1000\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 29s - loss: 0.5957 - cindex_score: 0.7260 - val_loss: 0.6277 - val_cindex_score: 0.7165\n",
      "Epoch 33/1000\n",
      "Epoch 00033: val_loss improved from 0.61815 to 0.60811, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 30s - loss: 0.5946 - cindex_score: 0.7248 - val_loss: 0.6081 - val_cindex_score: 0.7343\n",
      "Epoch 34/1000\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 29s - loss: 0.5969 - cindex_score: 0.7256 - val_loss: 0.6188 - val_cindex_score: 0.7259\n",
      "Epoch 35/1000\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 30s - loss: 0.5913 - cindex_score: 0.7259 - val_loss: 0.6216 - val_cindex_score: 0.7304\n",
      "Epoch 36/1000\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 29s - loss: 0.5911 - cindex_score: 0.7275 - val_loss: 0.6186 - val_cindex_score: 0.7165\n",
      "Epoch 37/1000\n",
      "Epoch 00037: val_loss improved from 0.60811 to 0.60040, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 30s - loss: 0.5844 - cindex_score: 0.7301 - val_loss: 0.6004 - val_cindex_score: 0.7335\n",
      "Epoch 38/1000\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 29s - loss: 0.5855 - cindex_score: 0.7298 - val_loss: 0.6335 - val_cindex_score: 0.7126\n",
      "Epoch 39/1000\n",
      "Epoch 00039: val_loss improved from 0.60040 to 0.59768, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 30s - loss: 0.5810 - cindex_score: 0.7316 - val_loss: 0.5977 - val_cindex_score: 0.7258\n",
      "Epoch 40/1000\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 30s - loss: 0.5739 - cindex_score: 0.7345 - val_loss: 0.6020 - val_cindex_score: 0.7402\n",
      "Epoch 41/1000\n",
      "Epoch 00041: val_loss improved from 0.59768 to 0.58795, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 30s - loss: 0.5747 - cindex_score: 0.7335 - val_loss: 0.5880 - val_cindex_score: 0.7242\n",
      "Epoch 42/1000\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 30s - loss: 0.5720 - cindex_score: 0.7355 - val_loss: 0.6021 - val_cindex_score: 0.7364\n",
      "Epoch 43/1000\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 29s - loss: 0.5718 - cindex_score: 0.7364 - val_loss: 0.6102 - val_cindex_score: 0.7232\n",
      "Epoch 44/1000\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 29s - loss: 0.5655 - cindex_score: 0.7405 - val_loss: 0.6004 - val_cindex_score: 0.7295\n",
      "Epoch 45/1000\n",
      "Epoch 00045: val_loss improved from 0.58795 to 0.58159, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 30s - loss: 0.5646 - cindex_score: 0.7397 - val_loss: 0.5816 - val_cindex_score: 0.7266\n",
      "Epoch 46/1000\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 29s - loss: 0.5736 - cindex_score: 0.7346 - val_loss: 0.5877 - val_cindex_score: 0.7366\n",
      "Epoch 47/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00047: val_loss did not improve\n",
      " - 30s - loss: 0.5611 - cindex_score: 0.7395 - val_loss: 0.6083 - val_cindex_score: 0.7237\n",
      "Epoch 48/1000\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 29s - loss: 0.5634 - cindex_score: 0.7418 - val_loss: 0.5845 - val_cindex_score: 0.7374\n",
      "Epoch 49/1000\n",
      "Epoch 00049: val_loss improved from 0.58159 to 0.57938, saving model to checkpoints/davis_dtc_dta.h5\n",
      " - 30s - loss: 0.5574 - cindex_score: 0.7427 - val_loss: 0.5794 - val_cindex_score: 0.7325\n",
      "Epoch 50/1000\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 29s - loss: 0.5540 - cindex_score: 0.7429 - val_loss: 0.5828 - val_cindex_score: 0.7264\n",
      "Epoch 51/1000\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 29s - loss: 0.5573 - cindex_score: 0.7422 - val_loss: 0.6048 - val_cindex_score: 0.7287\n",
      "Epoch 52/1000\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 30s - loss: 0.5586 - cindex_score: 0.7405 - val_loss: 0.6072 - val_cindex_score: 0.7296\n",
      "Epoch 53/1000\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 29s - loss: 0.5546 - cindex_score: 0.7428 - val_loss: 0.5992 - val_cindex_score: 0.7402\n",
      "Epoch 54/1000\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 30s - loss: 0.5494 - cindex_score: 0.7454 - val_loss: 0.5956 - val_cindex_score: 0.7381\n",
      "Epoch 55/1000\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 29s - loss: 0.5485 - cindex_score: 0.7450 - val_loss: 0.5848 - val_cindex_score: 0.7417\n",
      "Epoch 56/1000\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 30s - loss: 0.5480 - cindex_score: 0.7480 - val_loss: 0.5799 - val_cindex_score: 0.7417\n",
      "Epoch 57/1000\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 29s - loss: 0.5487 - cindex_score: 0.7453 - val_loss: 0.5893 - val_cindex_score: 0.7409\n",
      "Epoch 58/1000\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 30s - loss: 0.5473 - cindex_score: 0.7472 - val_loss: 0.5892 - val_cindex_score: 0.7060\n",
      "Epoch 59/1000\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 30s - loss: 0.5449 - cindex_score: 0.7468 - val_loss: 0.5949 - val_cindex_score: 0.7352\n"
     ]
    }
   ],
   "source": [
    "model_name='checkpoints/davis_dtc_dta'\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
    "checkpoint_callback = ModelCheckpoint(model_name+'.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "gridmodel = build_combined_categorical(FLAGS, FLAGS.num_windows, FLAGS.smi_window_lengths[0], FLAGS.seq_window_lengths[0])\n",
    "gridres = gridmodel.fit(([XD_train, XT_train ]), Y_train, batch_size=FLAGS.batch_size, epochs=1000, \n",
    "        validation_data=( ([np.array(XD_val), np.array(XT_val) ]), np.array(Y_val))\n",
    "           , callbacks=[early_stopping_callback, checkpoint_callback], verbose=2)\n",
    "\n",
    "gridmodel.save('davis_dtc_dta.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, auc, f1_score\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "gridmodel = load_model('checkpoints/davis_dtc_dta.h5')\n",
    "predicted_labels = gridmodel.predict([np.array(XD_val), np.array(XT_val) ])\n",
    "loss, rperf2 = gridmodel.evaluate(([np.array(XD_val),np.array(XT_val) ]), np.array(Y_val), verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cindex: [0.72608912]\n",
      "rmse: 0.7713228556107431\n",
      "f1: 0.6403685988913285\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = gridmodel.predict([np.array(XD_val), np.array(XT_val) ])\n",
    "print('cindex:', get_cindex(Y_val, predicted_labels))\n",
    "print('rmse:', np.sqrt(mean_squared_error(Y_val, predicted_labels)))\n",
    "#print('pearsonr:', pearsonr(Y_val, predicted_labels[:, 0]))\n",
    "#print('spearmanr:', np.sqrt(spearmanr(val_Y, predicted_labels[:, 0])))\n",
    "print('f1:', np.sqrt(f1_score(Y_val>7, predicted_labels>7)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "XD_test, XT_test = get_DTC_train('../data/dtc_test_for_deepDTA.csv', FLAGS.max_smi_len, FLAGS.max_seq_len, with_label=False)\n",
    "XD_test, XT_test = np.asarray(XD_test), np.asarray(XT_test)\n",
    "predicted_labels = gridmodel.predict([np.array(XD_test), np.array(XT_test) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data = pd.read_csv(data_path+'round_1_template.csv')\n",
    "submission_data.loc[:, 'pKd_[M]_pred'] = predicted_labels\n",
    "submission_data.to_csv('../data/submission_file3.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predicted_labels>7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
